import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from io import BytesIO
import time

# Configurazione pagina
st.set_page_config(page_title="Clustering Retail", layout="wide", page_icon="üõí")

# Titolo
st.title("üõí Segmentazione Clienti Retail")
st.markdown("""
Tool interattivo per segmentare la clientela retail utilizzando algoritmi di clustering.
""")

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configurazione")

    # Nuovi slider per generazione dati (come nello screenshot)
    st.subheader("Generazione Dati Simulati")
    num_clienti = st.slider("Numero di clienti:", 100, 2000, 1000)
    num_features_generazione = st.slider("Numero massimo di features per generazione (solo visivo):", 2, 10, 7) # Corrisponde alle nostre 7 feature

    algoritmo_selezionato = st.radio("Algoritmo:", ["K-Means", "DBSCAN"])

    # Selezione features
    features_disponibili = [
        "Et√†", "Reddito Annuale", "Visite Mensili",
        "Spesa Media", "% Acquisti Online",
        "Frequenza Acquisti", "Valore Carrello"
    ]
    features_selezionate = st.multiselect(
        "Seleziona caratteristiche per il clustering:",
        features_disponibili,
        default=["Et√†", "Reddito Annuale", "Visite Mensili"],
        max_selections=5
    )

    if algoritmo_selezionato == "K-Means":
        num_cluster = st.slider("Numero di cluster (K):", 2, 10, 4)
        max_iterazioni = st.slider("Massime iterazioni dell'algoritmo:", 1, 50, 20)
        random_seed_kmeans = st.number_input("Random seed:", min_value=0, value=42)

        mostra_evoluzione_cluster = st.checkbox("Mostra iterazioni dell'algoritmo")
        if mostra_evoluzione_cluster:
            st.markdown(f"Numero massimo di iterazioni: **{max_iterazioni}**")

    else: # DBSCAN
        epsilon = st.slider("Raggio (epsilon):", 0.1, 2.0, 0.5, step=0.05)
        min_campioni = st.slider("Minimo campioni:", 2, 20, 5)


# Generazione dati simulati
@st.cache_data
def genera_dati_dinamici(n_clienti_generati):
    np.random.seed(42)
    n = n_clienti_generati

    # Calcola le dimensioni di ogni quarto in modo che la somma sia esattamente n
    # Distribuire il resto se n non √® divisibile per 4
    segment_sizes = [n // 4] * 4
    remainder = n % 4
    for i in range(remainder):
        segment_sizes[i] += 1
    # Assicurati che la somma sia n
    assert sum(segment_sizes) == n, "Errore nel calcolo delle dimensioni dei segmenti"

    # Ora genera i dati usando le dimensioni corrette per ogni segmento
    dati = {
        "Et√†": np.round(np.concatenate([
            np.random.normal(loc=25, scale=3, size=segment_sizes[0]),
            np.random.normal(loc=40, scale=5, size=segment_sizes[1]),
            np.random.normal(loc=60, scale=7, size=segment_sizes[2]),
            np.random.normal(loc=35, scale=4, size=segment_sizes[3])
        ])),
        "Reddito Annuale": np.concatenate([
            np.random.normal(loc=40000, scale=5000, size=segment_sizes[0]),
            np.random.normal(loc=70000, scale=8000, size=segment_sizes[1]),
            np.random.normal(loc=35000, scale=4000, size=segment_sizes[2]),
            np.random.normal(loc=90000, scale=10000, size=segment_sizes[3])
        ]),
        "Visite Mensili": np.concatenate([
            np.random.poisson(15, size=segment_sizes[0]),
            np.random.poisson(8, size=segment_sizes[1]),
            np.random.poisson(5, size=segment_sizes[2]),
            np.random.poisson(20, size=segment_sizes[3])
        ]),
        "Spesa Media": np.concatenate([
            np.random.normal(loc=50, scale=10, size=segment_sizes[0]),
            np.random.normal(loc=120, scale=25, size=segment_sizes[1]),
            np.random.normal(loc=35, scale=8, size=segment_sizes[2]),
            np.random.normal(loc=200, scale=40, size=segment_sizes[3])
        ]),
        "% Acquisti Online": np.concatenate([
            np.random.uniform(0.7, 0.9, size=segment_sizes[0]),
            np.random.uniform(0.3, 0.5, size=segment_sizes[1]),
            np.random.uniform(0.1, 0.3, size=segment_sizes[2]),
            np.random.uniform(0.8, 1.0, size=segment_sizes[3])
        ]),
        "Frequenza Acquisti": np.concatenate([
            np.random.poisson(8, size=segment_sizes[0]),
            np.random.poisson(4, size=segment_sizes[1]),
            np.random.poisson(2, size=segment_sizes[2]),
            np.random.poisson(12, size=segment_sizes[3])
        ]),
        "Valore Carrello": np.concatenate([
            np.random.normal(loc=30, scale=5, size=segment_sizes[0]),
            np.random.normal(loc=80, scale=15, size=segment_sizes[1]),
            np.random.normal(loc=20, scale=4, size=segment_sizes[2]),
            np.random.normal(loc=150, scale=30, size=segment_sizes[3])
        ]),
        "Genere": np.random.choice(["M", "F"], size=n), # Questo deve avere esattamente 'n' elementi
        "Cluster Reale": np.repeat([1, 2, 3, 4], segment_sizes) # Usa segment_sizes qui
    }

    return pd.DataFrame(dati)

df = genera_dati_dinamici(num_clienti)

# Verifica che siano selezionate almeno 2 features
if len(features_selezionate) < 2:
    st.warning("Seleziona almeno 2 caratteristiche per il clustering!")
    st.stop()

# Preprocessing
scaler = StandardScaler()
X = scaler.fit_transform(df[features_selezionate])

# Riduzione dimensionale
riduzione_dimensionale_metodo_str = ""
if st.session_state.get('riduzione_dimensionale_metodo', 'PCA') == "PCA":
    riduttore = PCA(n_components=2)
    X_ridotto = riduttore.fit_transform(X)
    varianza_spiegata = riduttore.explained_variance_ratio_.sum() * 100
    riduzione_dimensionale_metodo_str = f"PCA (Varianza: {varianza_spiegata:.1f}%)"
else:
    riduttore = TSNE(n_components=2, perplexity=30, random_state=42, learning_rate='auto', init='random')
    X_ridotto = riduttore.fit_transform(X)
    riduzione_dimensionale_metodo_str = "t-SNE"

st.session_state['riduzione_dimensionale_metodo'] = riduzione_dimensionale_metodo_str

# Clustering
modello_clustering = None
labels = np.array([])
centers = None
convergenza_iterazioni = max_iterazioni

if algoritmo_selezionato == "K-Means":
    st.session_state['kmeans_states'] = {}

    modello_finale_kmeans = KMeans(n_clusters=num_cluster, max_iter=max_iterazioni, n_init='auto', random_state=random_seed_kmeans)
    modello_finale_kmeans.fit(X)
    convergenza_iterazioni = modello_finale_kmeans.n_iter_

    for i in range(1, max_iterazioni + 1):
        temp_kmeans = KMeans(n_clusters=num_cluster, max_iter=i, n_init=1, init='random', random_state=random_seed_kmeans)
        temp_labels = temp_kmeans.fit_predict(X)
        temp_centers_scaled = temp_kmeans.cluster_centers_

        st.session_state['kmeans_states'][i] = {
            'labels': temp_labels,
            'centers_scaled': temp_centers_scaled # Salva i centri scalati
        }

    labels = modello_finale_kmeans.labels_
    centers = scaler.inverse_transform(modello_finale_kmeans.cluster_centers_)


elif algoritmo_selezionato == "DBSCAN":
    modello_clustering = DBSCAN(eps=epsilon, min_samples=min_campioni)
    labels = modello_clustering.fit_predict(X)
    centers = None


# Calcolo metriche con gestione degli errori
silhouette_score_value = None
unique_labels = np.unique(labels)
if len(unique_labels) > 1 and (len(unique_labels) > 2 or -1 not in unique_labels):
    try:
        if -1 in unique_labels:
            X_filtered = X[labels != -1]
            labels_filtered = labels[labels != -1]
            if len(np.unique(labels_filtered)) > 1:
                 silhouette_score_value = silhouette_score(X_filtered, labels_filtered)
        else:
            silhouette_score_value = silhouette_score(X, labels)
    except ValueError:
        silhouette_score_value = None
else:
    silhouette_score_value = None


# Creazione DataFrame per plotting
plot_df = pd.DataFrame({
    "Componente_1": X_ridotto[:, 0],
    "Componente_2": X_ridotto[:, 1],
    "Cluster": labels.astype(str)
})

for feature in features_selezionate:
    plot_df[feature] = df[feature]

# Visualizzazione
tab1, tab2, tab3 = st.tabs(["üìä Risultati", "üìà Analisi", "‚ùì Guida"])

with tab1:
    st.header("Risultati Clustering")

    if algoritmo_selezionato == "K-Means" and mostra_evoluzione_cluster:
        st.subheader("Evoluzione delle Iterazioni dell'Algoritmo K-Means")
        st.info(f"L'algoritmo converge in {convergenza_iterazioni} iterazioni (su un massimo di {max_iterazioni}).")

        # Slider per selezionare l'iterazione
        iterazione_corrente = st.slider(
            "Seleziona iterazione:",
            1,
            max_iterazioni,
            max_iterazioni # Default: mostra lo stato finale
        )

        if 'animazione_in_corso' not in st.session_state:
            st.session_state['animazione_in_corso'] = False

        col_anim, col_filler = st.columns([1, 3])
        with col_anim:
            avvia_animazione = st.checkbox("Avvia Animazione")

        if avvia_animazione:
            st.session_state['animazione_in_corso'] = True
            grafico_placeholder = st.empty()
            for i in range(1, max_iterazioni + 1):
                if not st.session_state['animazione_in_corso']: # Permette di interrompere l'animazione
                    break
                temp_labels_anim = st.session_state['kmeans_states'][i]['labels']
                temp_centers_anim_scaled = st.session_state['kmeans_states'][i]['centers_scaled']

                plot_df_anim = pd.DataFrame({
                    "Componente_1": X_ridotto[:, 0],
                    "Componente_2": X_ridotto[:, 1],
                    "Cluster": temp_labels_anim.astype(str)
                })

                fig_anim = px.scatter(
                    plot_df_anim,
                    x="Componente_1",
                    y="Componente_2",
                    color="Cluster",
                    title=f"Iterazione {i}/{max_iterazioni} ({riduzione_dimensionale_metodo_str})",
                    labels={"Componente_1": "Prima Componente Principale", "Componente_2": "Seconda Componente Principale", "Cluster": "Cluster"},
                    hover_data=features_selezionate
                )
                if temp_centers_anim_scaled is not None:
                    centers_reduced_anim = riduttore.transform(temp_centers_anim_scaled)
                    fig_anim.add_scatter(x=centers_reduced_anim[:, 0], y=centers_reduced_anim[:, 1],
                                    mode='markers', marker=dict(symbol='x', size=15, color='black'),
                                    name='Centroidi', showlegend=True)

                with grafico_placeholder:
                    st.plotly_chart(fig_anim, use_container_width=True)
                time.sleep(0.5)
            st.success("Animazione completata!")
            st.session_state['animazione_in_corso'] = False # Resetta lo stato dell'animazione
        else:
            st.session_state['animazione_in_corso'] = False # Assicurati che sia falso se la checkbox √® deselezionata

        # Visualizzazione singola iterazione selezionata (se non in animazione)
        if not st.session_state['animazione_in_corso']:
            selected_labels = st.session_state['kmeans_states'][iterazione_corrente]['labels']
            selected_centers_scaled = st.session_state['kmeans_states'][iterazione_corrente]['centers_scaled']

            plot_df_selected = pd.DataFrame({
                "Componente_1": X_ridotto[:, 0],
                "Componente_2": X_ridotto[:, 1],
                "Cluster": selected_labels.astype(str)
            })

            fig_selected = px.scatter(
                plot_df_selected,
                x="Componente_1",
                y="Componente_2",
                color="Cluster",
                title=f"Iterazione {iterazione_corrente}/{max_iterazioni} ({riduzione_dimensionale_metodo_str})",
                labels={"Componente_1": "Prima Componente Principale", "Componente_2": "Seconda Componente Principale", "Cluster": "Cluster"},
                hover_data=features_selezionate
            )
            if selected_centers_scaled is not None:
                centers_reduced = riduttore.transform(selected_centers_scaled)
                fig_selected.add_scatter(x=centers_reduced[:, 0], y=centers_reduced[:, 1],
                                mode='markers', marker=dict(symbol='x', size=15, color='black'),
                                name='Centroidi', showlegend=True)

            st.plotly_chart(fig_selected, use_container_width=True)

    else: # K-Means senza evoluzione o DBSCAN
        col1, col2 = st.columns([2, 1])

        with col1:
            try:
                fig = px.scatter(
                    plot_df,
                    x="Componente_1",
                    y="Componente_2",
                    color="Cluster",
                    title=f"Risultati Clustering ({riduzione_dimensionale_metodo_str})",
                    labels={
                        "Componente_1": "Prima Componente Principale",
                        "Componente_2": "Seconda Componente Principale",
                        "Cluster": "Cluster"
                    },
                    hover_data=features_selezionate,
                    color_discrete_map={'-1': 'grey'} if algoritmo_selezionato == "DBSCAN" else None
                )
                if algoritmo_selezionato == "K-Means" and centers is not None:
                    centers_scaled = scaler.transform(centers) # Assicurati di usare i centri SCALATI per la riduzione dimensionale
                    centers_reduced = riduttore.transform(centers_scaled)
                    fig.add_scatter(x=centers_reduced[:, 0], y=centers_reduced[:, 1],
                                    mode='markers', marker=dict(symbol='x', size=15, color='black'),
                                    name='Centroidi', showlegend=True)

                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"Errore nella creazione del grafico: {str(e)}")
                fig, ax = plt.subplots()
                scatter = ax.scatter(X_ridotto[:, 0], X_ridotto[:, 1], c=labels, cmap='viridis')
                ax.set_title(f"Risultati Clustering ({riduzione_dimensionale_metodo_str})")
                ax.set_xlabel("Componente 1")
                ax.set_ylabel("Componente 2")
                plt.colorbar(scatter, ax=ax, label='Cluster')
                st.pyplot(fig)

        with col2:
            st.subheader("Metriche")
            if silhouette_score_value is not None:
                st.metric("Silhouette Score",
                         f"{silhouette_score_value:.3f}",
                         help="Valore tra -1 e 1: pi√π alto √® meglio. I valori negativi indicano che i punti potrebbero essere stati assegnati al cluster sbagliato, mentre i valori vicini a 0 indicano cluster sovrapposti. Per DBSCAN, i punti di rumore (-1) vengono esclusi dal calcolo.")
            else:
                st.metric("Silhouette Score",
                         "N/A",
                         help="Non calcolabile: richiede almeno 2 cluster validi (non solo rumore o un singolo cluster).")

            st.subheader("Distribuzione Cluster")
            cluster_counts = pd.Series(labels).value_counts().sort_index()
            st.bar_chart(cluster_counts)

            if algoritmo_selezionato == "DBSCAN" and '-1' in cluster_counts.index.astype(str):
                st.info("Nota: Il cluster '-1' in DBSCAN rappresenta i punti di rumore (outlier).")

            st.write(f"Caratteristiche utilizzate: {', '.join(features_selezionate)}")

with tab2:
    st.header("Analisi Dettagliata")

    df["Cluster"] = labels

    st.subheader("Statistiche per Cluster")
    if algoritmo_selezionato == "DBSCAN" and -1 in df["Cluster"].unique():
        st.dataframe(
            df[df["Cluster"] != -1].groupby("Cluster")[features_selezionate]
            .agg(["mean", "median", "std"])
            .style.background_gradient(cmap="Blues")
        )
        st.info("Le statistiche medie per il cluster '-1' (rumore) non sono incluse in questa tabella, poich√© non rappresenta un cluster tradizionale.")
    else:
        st.dataframe(
            df.groupby("Cluster")[features_selezionate]
            .agg(["mean", "median", "std"])
            .style.background_gradient(cmap="Blues")
        )

    st.subheader("Distribuzione Caratteristiche per Cluster")
    caratteristica_selezionata = st.selectbox("Seleziona caratteristica:", features_selezionate)
    fig_box = px.box(df, x="Cluster", y=caratteristica_selezionata, color="Cluster", title=f"Distribuzione di '{caratteristica_selezionata}' per Cluster")
    st.plotly_chart(fig_box, use_container_width=True)

with tab3:
    st.header("Guida all'Uso")

    st.markdown("""
    ### Come utilizzare questo strumento:
    1.  **Generazione Dati Simulati**: Controlla la dimensione del dataset generato.
    2.  **Seleziona le caratteristiche** che vuoi usare per il clustering (max 5) nella sidebar.
    3.  **Scegli l'algoritmo** preferito nella sidebar:
        * **K-Means**: adatto per cluster sferici di dimensioni simili. Richiede di specificare il numero di cluster (`Numero di cluster`). Puoi anche impostare un `Random seed` per risultati riproducibili.
        * **DBSCAN**: ideale per cluster di forma arbitraria e per l'identificazione di punti di rumore (outlier). Richiede `Raggio (epsilon)` (distanza massima tra due campioni per essere considerati nella stessa vicinanza) e `Minimo campioni` (numero di campioni in una vicinanza per un punto per essere considerato un punto core).
    4.  **Regola i parametri** specifici dell'algoritmo selezionato nella sidebar.
    5.  L'analisi si aggiorner√† automaticamente ad ogni modifica dei parametri.
    """)

    st.subheader("Interpretazione dei Risultati:")
    st.markdown("""
    * **Silhouette Score**: √à una metrica che misura la qualit√† del clustering. Varia tra -1 e 1.
        * **Valori vicino a +1**: Indicano che i punti sono ben separati e formano cluster distinti.
        * **Valori vicino a 0**: Suggeriscono che i cluster si sovrappongono o che i punti si trovano al limite tra due cluster.
        * **Valori vicino a -1**: Indicano che i punti potrebbero essere stati assegnati al cluster sbagliato.
        * Per DBSCAN, i punti di rumore (cluster '-1') non vengono inclusi nel calcolo del Silhouette Score.
    * **Grafici dei Cluster**: Mostrano la distribuzione dei dati nel nuovo spazio a 2 dimensioni dopo la riduzione dimensionale (PCA o t-SNE). Cluster simili indicano segmenti di clienti con comportamenti o caratteristiche simili.
    * **Distribuzione Cluster**: Un istogramma che mostra quanti punti ci sono in ogni cluster.
    * **Statistiche per Cluster**: Le tabelle mostrano le medie, mediane e deviazioni standard delle caratteristiche selezionate per ogni cluster. Questo ti aiuta a capire il "profilo" di ogni segmento di clientela (es. "Clienti giovani ad alto reddito", "Anziani con bassa frequenza di acquisto").
    * **Cluster '-1' (DBSCAN)**: Se utilizzi DBSCAN, potresti vedere un cluster etichettato '-1'. Questi sono i **punti di rumore (outlier)** che non sono stati assegnati a nessun cluster denso.
    """)

    st.subheader("Descrizione Caratteristiche")
    descrizioni = {
        "Et√†": "Et√† del cliente (arrotondata all'intero pi√π vicino)",
        "Reddito Annuale": "Reddito annuale stimato in ‚Ç¨",
        "Visite Mensili": "Numero di visite al negozio/mese",
        "Spesa Media": "Spesa media per visita in ‚Ç¨",
        "% Acquisti Online": "Percentuale di acquisti fatti online",
        "Frequenza Acquisti": "Numero di acquisti mensili",
        "Valore Carrello": "Valore medio del carrello in ‚Ç¨"
    }

    for feat in features_selezionate:
        st.markdown(f"**{feat}**: {descrizioni.get(feat, '')}")

# Footer
st.markdown("---")
st.markdown("Progetto di Data Science - Universit√† IULM | [GitHub](https://github.com/)")
